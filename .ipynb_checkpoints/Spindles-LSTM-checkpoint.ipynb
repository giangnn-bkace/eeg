{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply LSTM model to classify Spindles Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages need to be installed\n",
    "\n",
    "```shell\n",
    "> conda install numpy pandas tensorflow-gpu scikit-learn\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the CSV data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to the dataset\n",
    "DATA_PATH = \"data_excerpt1.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "data = pd.read_csv(DATA_PATH, header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check if the data is correctly loaded\n",
    "First 10 rows of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>491</th>\n",
       "      <th>492</th>\n",
       "      <th>493</th>\n",
       "      <th>494</th>\n",
       "      <th>495</th>\n",
       "      <th>496</th>\n",
       "      <th>497</th>\n",
       "      <th>498</th>\n",
       "      <th>499</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.9562</td>\n",
       "      <td>-0.8962</td>\n",
       "      <td>-3.1877</td>\n",
       "      <td>-4.1783</td>\n",
       "      <td>-5.3190</td>\n",
       "      <td>-6.1896</td>\n",
       "      <td>-7.8006</td>\n",
       "      <td>-6.9701</td>\n",
       "      <td>-0.7061</td>\n",
       "      <td>2.3058</td>\n",
       "      <td>...</td>\n",
       "      <td>6.1483</td>\n",
       "      <td>6.0882</td>\n",
       "      <td>1.1451</td>\n",
       "      <td>-2.5673</td>\n",
       "      <td>0.7148</td>\n",
       "      <td>6.9588</td>\n",
       "      <td>4.8775</td>\n",
       "      <td>-2.9575</td>\n",
       "      <td>-7.4704</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-8.8313</td>\n",
       "      <td>-8.5511</td>\n",
       "      <td>-6.5198</td>\n",
       "      <td>-4.1983</td>\n",
       "      <td>2.2958</td>\n",
       "      <td>6.1183</td>\n",
       "      <td>5.2477</td>\n",
       "      <td>3.8268</td>\n",
       "      <td>2.6561</td>\n",
       "      <td>2.7161</td>\n",
       "      <td>...</td>\n",
       "      <td>3.6667</td>\n",
       "      <td>-1.2364</td>\n",
       "      <td>-6.6799</td>\n",
       "      <td>-4.0282</td>\n",
       "      <td>-1.8968</td>\n",
       "      <td>-4.3584</td>\n",
       "      <td>-3.7580</td>\n",
       "      <td>-0.8362</td>\n",
       "      <td>-6.4598</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-12.7638</td>\n",
       "      <td>-7.7906</td>\n",
       "      <td>-5.7993</td>\n",
       "      <td>-9.7518</td>\n",
       "      <td>-5.4891</td>\n",
       "      <td>-3.3878</td>\n",
       "      <td>-5.4791</td>\n",
       "      <td>-3.9381</td>\n",
       "      <td>-4.6186</td>\n",
       "      <td>-5.0589</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.8000</td>\n",
       "      <td>-6.3097</td>\n",
       "      <td>-4.8687</td>\n",
       "      <td>-2.7074</td>\n",
       "      <td>-1.0463</td>\n",
       "      <td>-2.3972</td>\n",
       "      <td>0.6148</td>\n",
       "      <td>5.4378</td>\n",
       "      <td>4.3371</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.5647</td>\n",
       "      <td>1.2752</td>\n",
       "      <td>2.1357</td>\n",
       "      <td>0.8049</td>\n",
       "      <td>3.6467</td>\n",
       "      <td>2.2358</td>\n",
       "      <td>-2.2170</td>\n",
       "      <td>1.7355</td>\n",
       "      <td>4.7074</td>\n",
       "      <td>3.8268</td>\n",
       "      <td>...</td>\n",
       "      <td>2.9562</td>\n",
       "      <td>7.6292</td>\n",
       "      <td>1.3252</td>\n",
       "      <td>-3.0876</td>\n",
       "      <td>3.0463</td>\n",
       "      <td>-1.8468</td>\n",
       "      <td>-1.8168</td>\n",
       "      <td>-2.1770</td>\n",
       "      <td>-6.6098</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-3.9882</td>\n",
       "      <td>-5.1989</td>\n",
       "      <td>-10.8325</td>\n",
       "      <td>-11.8732</td>\n",
       "      <td>-8.7412</td>\n",
       "      <td>-7.9107</td>\n",
       "      <td>-4.7687</td>\n",
       "      <td>-4.1183</td>\n",
       "      <td>-7.0001</td>\n",
       "      <td>-5.2490</td>\n",
       "      <td>...</td>\n",
       "      <td>2.3258</td>\n",
       "      <td>2.3459</td>\n",
       "      <td>-1.1364</td>\n",
       "      <td>-4.6386</td>\n",
       "      <td>-4.6486</td>\n",
       "      <td>-0.5560</td>\n",
       "      <td>-0.7661</td>\n",
       "      <td>-3.8881</td>\n",
       "      <td>-4.3184</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-6.4698</td>\n",
       "      <td>-8.9013</td>\n",
       "      <td>-8.0708</td>\n",
       "      <td>-3.5679</td>\n",
       "      <td>-4.1683</td>\n",
       "      <td>-7.6505</td>\n",
       "      <td>-5.6793</td>\n",
       "      <td>-2.2471</td>\n",
       "      <td>1.2051</td>\n",
       "      <td>-6.8100</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7749</td>\n",
       "      <td>2.3058</td>\n",
       "      <td>7.8594</td>\n",
       "      <td>3.7568</td>\n",
       "      <td>-4.2383</td>\n",
       "      <td>-2.6573</td>\n",
       "      <td>4.6873</td>\n",
       "      <td>3.2764</td>\n",
       "      <td>-0.7961</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-2.3271</td>\n",
       "      <td>-6.3097</td>\n",
       "      <td>-6.7699</td>\n",
       "      <td>-4.6586</td>\n",
       "      <td>-2.6573</td>\n",
       "      <td>1.0050</td>\n",
       "      <td>3.3165</td>\n",
       "      <td>4.7174</td>\n",
       "      <td>5.8581</td>\n",
       "      <td>5.5579</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.0169</td>\n",
       "      <td>1.3152</td>\n",
       "      <td>0.5847</td>\n",
       "      <td>-2.6373</td>\n",
       "      <td>-5.8994</td>\n",
       "      <td>-4.0982</td>\n",
       "      <td>-4.9288</td>\n",
       "      <td>-10.1921</td>\n",
       "      <td>-11.4629</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-9.7318</td>\n",
       "      <td>-7.2903</td>\n",
       "      <td>-3.3878</td>\n",
       "      <td>1.8656</td>\n",
       "      <td>2.9562</td>\n",
       "      <td>4.3872</td>\n",
       "      <td>12.3822</td>\n",
       "      <td>15.8545</td>\n",
       "      <td>13.8732</td>\n",
       "      <td>14.3035</td>\n",
       "      <td>...</td>\n",
       "      <td>10.5511</td>\n",
       "      <td>11.9920</td>\n",
       "      <td>10.8112</td>\n",
       "      <td>8.6999</td>\n",
       "      <td>6.8787</td>\n",
       "      <td>2.4059</td>\n",
       "      <td>1.4653</td>\n",
       "      <td>2.7261</td>\n",
       "      <td>0.7949</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.2758</td>\n",
       "      <td>7.7793</td>\n",
       "      <td>12.0220</td>\n",
       "      <td>9.9707</td>\n",
       "      <td>4.5072</td>\n",
       "      <td>0.4747</td>\n",
       "      <td>-3.3378</td>\n",
       "      <td>-6.5798</td>\n",
       "      <td>-8.4810</td>\n",
       "      <td>-7.9307</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.3359</td>\n",
       "      <td>4.0569</td>\n",
       "      <td>2.9562</td>\n",
       "      <td>-3.3578</td>\n",
       "      <td>-1.9369</td>\n",
       "      <td>-2.9275</td>\n",
       "      <td>-4.6486</td>\n",
       "      <td>-2.7674</td>\n",
       "      <td>-1.1764</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-7.0801</td>\n",
       "      <td>-4.2884</td>\n",
       "      <td>1.2852</td>\n",
       "      <td>-2.1870</td>\n",
       "      <td>-0.0257</td>\n",
       "      <td>2.5960</td>\n",
       "      <td>2.9462</td>\n",
       "      <td>-1.2064</td>\n",
       "      <td>-3.0176</td>\n",
       "      <td>-0.0457</td>\n",
       "      <td>...</td>\n",
       "      <td>11.9220</td>\n",
       "      <td>9.6505</td>\n",
       "      <td>6.9088</td>\n",
       "      <td>13.2828</td>\n",
       "      <td>13.0827</td>\n",
       "      <td>12.1021</td>\n",
       "      <td>11.9420</td>\n",
       "      <td>9.2402</td>\n",
       "      <td>10.7712</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 501 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0       1        2        3       4       5        6        7  \\\n",
       "0  -0.9562 -0.8962  -3.1877  -4.1783 -5.3190 -6.1896  -7.8006  -6.9701   \n",
       "1  -8.8313 -8.5511  -6.5198  -4.1983  2.2958  6.1183   5.2477   3.8268   \n",
       "2 -12.7638 -7.7906  -5.7993  -9.7518 -5.4891 -3.3878  -5.4791  -3.9381   \n",
       "3   0.5647  1.2752   2.1357   0.8049  3.6467  2.2358  -2.2170   1.7355   \n",
       "4  -3.9882 -5.1989 -10.8325 -11.8732 -8.7412 -7.9107  -4.7687  -4.1183   \n",
       "5  -6.4698 -8.9013  -8.0708  -3.5679 -4.1683 -7.6505  -5.6793  -2.2471   \n",
       "6  -2.3271 -6.3097  -6.7699  -4.6586 -2.6573  1.0050   3.3165   4.7174   \n",
       "7  -9.7318 -7.2903  -3.3878   1.8656  2.9562  4.3872  12.3822  15.8545   \n",
       "8   2.2758  7.7793  12.0220   9.9707  4.5072  0.4747  -3.3378  -6.5798   \n",
       "9  -7.0801 -4.2884   1.2852  -2.1870 -0.0257  2.5960   2.9462  -1.2064   \n",
       "\n",
       "         8        9  ...      491      492      493      494      495  \\\n",
       "0  -0.7061   2.3058  ...   6.1483   6.0882   1.1451  -2.5673   0.7148   \n",
       "1   2.6561   2.7161  ...   3.6667  -1.2364  -6.6799  -4.0282  -1.8968   \n",
       "2  -4.6186  -5.0589  ...  -6.8000  -6.3097  -4.8687  -2.7074  -1.0463   \n",
       "3   4.7074   3.8268  ...   2.9562   7.6292   1.3252  -3.0876   3.0463   \n",
       "4  -7.0001  -5.2490  ...   2.3258   2.3459  -1.1364  -4.6386  -4.6486   \n",
       "5   1.2051  -6.8100  ...   0.7749   2.3058   7.8594   3.7568  -4.2383   \n",
       "6   5.8581   5.5579  ...  -2.0169   1.3152   0.5847  -2.6373  -5.8994   \n",
       "7  13.8732  14.3035  ...  10.5511  11.9920  10.8112   8.6999   6.8787   \n",
       "8  -8.4810  -7.9307  ...  -0.3359   4.0569   2.9562  -3.3578  -1.9369   \n",
       "9  -3.0176  -0.0457  ...  11.9220   9.6505   6.9088  13.2828  13.0827   \n",
       "\n",
       "       496      497      498      499  Label  \n",
       "0   6.9588   4.8775  -2.9575  -7.4704      5  \n",
       "1  -4.3584  -3.7580  -0.8362  -6.4598      5  \n",
       "2  -2.3972   0.6148   5.4378   4.3371      5  \n",
       "3  -1.8468  -1.8168  -2.1770  -6.6098      5  \n",
       "4  -0.5560  -0.7661  -3.8881  -4.3184      5  \n",
       "5  -2.6573   4.6873   3.2764  -0.7961      5  \n",
       "6  -4.0982  -4.9288 -10.1921 -11.4629      5  \n",
       "7   2.4059   1.4653   2.7261   0.7949      5  \n",
       "8  -2.9275  -4.6486  -2.7674  -1.1764      5  \n",
       "9  12.1021  11.9420   9.2402  10.7712      5  \n",
       "\n",
       "[10 rows x 501 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seperate features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.asarray(data.iloc[:,:-1])\n",
    "y = np.asarray(data.iloc[:,-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seperate training data and test data\n",
    "\n",
    "Using cross_validation functions from Scikit-learn package\n",
    "\n",
    "For simple, I used train_test_split to split the data (not use k-fold cross-vaildation yet).\n",
    "I splitted 1/4 of the data as test data (because there are only 4 samples of class 0)\n",
    "\n",
    "For other cross-validation methods, please check this link: https://scikit-learn.org/stable/modules/cross_validation.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, \n",
    "                                                    y, \n",
    "                                                    test_size=0.25, \n",
    "                                                    random_state=0,\n",
    "                                                    stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((270, 500), (90, 500), (270,), (90,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constant for create model\n",
    "Do not change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_FEATURES = x.shape[1]\n",
    "NUM_CLASSES = len(np.unique(y))\n",
    "NUM_TRAIN_SAMPLE = y_train.shape[0]\n",
    "NUM_TEST_SAMPLE = y_test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model\n",
    "A simple model with only 1 LSTM layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of nodes in the LSTM layer\n",
    "# You can change this\n",
    "LSTM_SIZE = 10\n",
    "\n",
    "# Dropout probability\n",
    "# You can change it in range [0,1]\n",
    "DROPOUT = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\giang\\Anaconda3\\envs\\eeg\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\giang\\Anaconda3\\envs\\eeg\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape (Reshape)            (None, 500, 1)            0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 10)                480       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 5)                 55        \n",
      "=================================================================\n",
      "Total params: 535\n",
      "Trainable params: 535\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "model.add(tf.keras.layers.Reshape((NUM_FEATURES, 1), input_shape=(NUM_FEATURES,)))\n",
    "model.add(tf.keras.layers.LSTM(LSTM_SIZE, return_sequences=False, input_shape=(NUM_FEATURES, 1)))\n",
    "model.add(tf.keras.layers.Dropout(DROPOUT))\n",
    "model.add(tf.keras.layers.Dense(NUM_CLASSES, activation='softmax'))\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data to train and test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch size\n",
    "# you can change this\n",
    "BATCH_SIZE = 10\n",
    "\n",
    "# number of epochs to train the model\n",
    "# you can change this\n",
    "NUM_EPOCHS = 100\n",
    "\n",
    "# do not change this\n",
    "PER_EPOCH_STEPS = NUM_TRAIN_SAMPLE//BATCH_SIZE\n",
    "TEST_PER_EPOCH_STEPS = NUM_TEST_SAMPLE//BATCH_SIZE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create tensorflow data to train and test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 1 2 1 5 2 5 1 2 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(y_train[:10])\n",
    "encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "y_new = encoder.fit_transform(y_train.reshape(-1,1)).toarray()\n",
    "y_new[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode class labels as one-hot vectors\n",
    "encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "y_train = encoder.fit_transform(y_train.reshape(-1,1)).toarray()\n",
    "y_test = encoder.fit_transform(y_test.reshape(-1,1)).toarray()\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
    "\n",
    "train_dataset = train_dataset.shuffle(NUM_TRAIN_SAMPLE)\n",
    "train_dataset = train_dataset.repeat().batch(BATCH_SIZE)\n",
    "\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE).repeat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure the optimizer to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning rate\n",
    "# you can train this\n",
    "LEARNING_RATE = 1e-3\n",
    "\n",
    "# Using Adam optimizer\n",
    "# and categorical_crossentropy as loss function\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(LEARNING_RATE), \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\giang\\Anaconda3\\envs\\eeg\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/300\n",
      "27/27 [==============================] - 11s 400ms/step - loss: 1.5571 - acc: 0.2926 - val_loss: 1.4469 - val_acc: 0.5111\n",
      "Epoch 2/300\n",
      "27/27 [==============================] - 9s 335ms/step - loss: 1.4361 - acc: 0.4926 - val_loss: 1.3530 - val_acc: 0.6222\n",
      "Epoch 3/300\n",
      "27/27 [==============================] - 9s 328ms/step - loss: 1.3386 - acc: 0.5704 - val_loss: 1.2801 - val_acc: 0.6222\n",
      "Epoch 4/300\n",
      "27/27 [==============================] - 9s 328ms/step - loss: 1.2624 - acc: 0.6000 - val_loss: 1.2290 - val_acc: 0.6111\n",
      "Epoch 5/300\n",
      "27/27 [==============================] - 9s 327ms/step - loss: 1.2032 - acc: 0.6111 - val_loss: 1.1938 - val_acc: 0.6222\n",
      "Epoch 6/300\n",
      "27/27 [==============================] - 9s 327ms/step - loss: 1.1632 - acc: 0.6111 - val_loss: 1.1678 - val_acc: 0.6111\n",
      "Epoch 7/300\n",
      "16/27 [================>.............] - ETA: 3s - loss: 1.1129 - acc: 0.6313"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-3bc18973da62>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mPER_EPOCH_STEPS\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m           validation_steps=TEST_PER_EPOCH_STEPS)\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\eeg\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    878\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 880\u001b[1;33m           validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m    881\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\eeg\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, mode, validation_in_fit, **kwargs)\u001b[0m\n\u001b[0;32m    264\u001b[0m           \u001b[1;31m# `ins` can be callable in DistributionStrategy + eager case.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m           \u001b[0mactual_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mins\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 266\u001b[1;33m           \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactual_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    267\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    268\u001b[0m           logging.warning('Your dataset iterator ran out of data; '\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\eeg\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3074\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3075\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 3076\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   3077\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3078\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\eeg\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(train_dataset, \n",
    "          epochs=NUM_EPOCHS, \n",
    "          steps_per_epoch=PER_EPOCH_STEPS, \n",
    "          validation_data=test_dataset, \n",
    "          validation_steps=TEST_PER_EPOCH_STEPS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eeg",
   "language": "python",
   "name": "eeg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
